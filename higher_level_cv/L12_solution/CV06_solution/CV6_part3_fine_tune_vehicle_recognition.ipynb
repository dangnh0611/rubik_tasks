{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment 12_Solution.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"vtZuKiI-r2rI","colab_type":"text"},"source":["# 3. Tìm hiểu kỹ thuật sử dụng các mô hình mạng CNN kinh điển như VGG, ResNet, DenseNet với framework Keras, thử áp dụng cho các bài toán nhận diện cảm xúc, phân loại phương tiện giao thông:\n","https://keras.io/applications/\n"]},{"cell_type":"markdown","metadata":{"id":"uj2pYYWgZ3d7","colab_type":"text"},"source":["# Phân loại phương tiện giao thông "]},{"cell_type":"code","metadata":{"id":"3fvL9RQzr6c1","colab_type":"code","outputId":"498c9998-2d39-4f5d-fad6-d9864a2387f2","executionInfo":{"status":"ok","timestamp":1561891891081,"user_tz":-420,"elapsed":23135,"user":{"displayName":"Đăng Nguyễn Hồng","photoUrl":"https://lh5.googleusercontent.com/-UTwxFgcfKfI/AAAAAAAAAAI/AAAAAAAAACY/UhcN1_QeVrs/s64/photo.jpg","userId":"01453617082147037162"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6JHrbacEr7JJ","colab_type":"code","outputId":"fff90a5d-8eea-43c5-9e42-fa4134bbd839","executionInfo":{"status":"ok","timestamp":1561891891086,"user_tz":-420,"elapsed":23118,"user":{"displayName":"Đăng Nguyễn Hồng","photoUrl":"https://lh5.googleusercontent.com/-UTwxFgcfKfI/AAAAAAAAAAI/AAAAAAAAACY/UhcN1_QeVrs/s64/photo.jpg","userId":"01453617082147037162"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd /content/drive/My Drive/Colab Notebooks/L12"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/L12\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kyLK3tzYr2rK","colab_type":"code","outputId":"d9b24f9c-8839-4433-9721-f65c589b1657","executionInfo":{"status":"ok","timestamp":1561891893326,"user_tz":-420,"elapsed":25346,"user":{"displayName":"Đăng Nguyễn Hồng","photoUrl":"https://lh5.googleusercontent.com/-UTwxFgcfKfI/AAAAAAAAAAI/AAAAAAAAACY/UhcN1_QeVrs/s64/photo.jpg","userId":"01453617082147037162"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import keras\n","from keras.layers.core import Dense, Dropout, Activation, Flatten\n","from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n","from keras.layers.normalization import BatchNormalization\n","from keras.regularizers import l2"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Tfenhkh8r2rS","colab_type":"text"},"source":["## Hàm đọc dữ liệu (training set and test set)\n","Bộ dữ liệu của bài toán được đặt ở thư mục './Dataset/vehicle'. Trong thư mục này ta có 2 thư mục con: Training, Testing tương ứng với dữ liệu để huấn luyện mô hình và dữ liệu để kiểm tra độ chính xác của mô hình. "]},{"cell_type":"code","metadata":{"id":"NmSm06nKr2rT","colab_type":"code","colab":{}},"source":["import numpy as np\n","import os\n","import cv2\n","import pickle\n","\n","def prepair_data(path='./Dataset/vehicle', img_shape=(32, 32)):\n","    TRAINING_DATA_PATH = os.path.join(path, 'Training')\n","    TESTING_DATA_PATH = os.path.join(path, 'Testing')\n","\n","    x_train = []\n","    y_train = []\n","    x_test = []\n","    y_test = []\n","\n","    label_id = 0\n","    \n","    num_classes = len(os.listdir(TRAINING_DATA_PATH))\n","    for label in os.listdir(TRAINING_DATA_PATH):\n","\n","        # Read training data\n","        for img_file in os.listdir(os.path.join(TRAINING_DATA_PATH, label)):\n","            print(img_file)\n","            img = cv2.imread(os.path.join(TRAINING_DATA_PATH, label, img_file))\n","            img = cv2.resize(img, img_shape)\n","            x_train.append(img)\n","\n","            y = np.zeros(num_classes)\n","            y[label_id] = 1\n","            y_train.append(y)\n","\n","        # Read testing data\n","        for img_file in os.listdir(os.path.join(TESTING_DATA_PATH, label)):\n","            print(img_file)\n","            img = cv2.imread(os.path.join(TESTING_DATA_PATH, label, img_file))\n","            img = cv2.resize(img, img_shape)\n","            x_test.append(img)\n","\n","            y = np.zeros(num_classes)\n","            y[label_id] = 1\n","            y_test.append(y)\n","\n","        label_id += 1\n","\n","    return np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Asm2vlm5F23K","colab_type":"text"},"source":["Đọc dữ liệu"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"3Ee-3ZjLr2rY","colab_type":"code","outputId":"fee1d293-a15b-4b91-a5dd-227a52003068","executionInfo":{"status":"ok","timestamp":1561891893733,"user_tz":-420,"elapsed":25729,"user":{"displayName":"Đăng Nguyễn Hồng","photoUrl":"https://lh5.googleusercontent.com/-UTwxFgcfKfI/AAAAAAAAAAI/AAAAAAAAACY/UhcN1_QeVrs/s64/photo.jpg","userId":"01453617082147037162"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["dataset=()\n","filename=os.path.join('Dataset','vehicle.pkl')\n","if not os.path.isfile(filename):\n","  x_train, y_train, x_test, y_test = prepair_data(path='./Dataset/vehicle', img_shape=(32, 32))\n","  data_set=(x_train,y_train,x_test,y_test)\n","  pickle.dump(data_set,open(filename,'wb'))\n","else:\n","  x_train, y_train, x_test, y_test=pickle.load(open(filename,'rb'))\n","\n","print(x_train.shape)\n","print(y_train.shape)\n","print(x_test.shape)\n","print(y_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(1672, 32, 32, 3)\n","(1672, 5)\n","(183, 32, 32, 3)\n","(183, 5)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jfIOhXcJGJKx","colab_type":"text"},"source":["# Kĩ thuật fine-tune sử dụng các mô hình đã được huấn luyện sẵn\n","Keras cung cấp các mô hình kinh điển cho tập dữ liệu ImageNet với 1000 classes.   \n","Vì các mô hinh này là các bộ phân loại mạnh, nên đặc trưng trích xuất từ các mô hình này ( trước tầng fully-connected) là rất tốt và cho khả năng trích xuất đặc trưng cao. Xây dựng mô hình phân loại phương tiện giao thông trong đó tận dụng bộ trích xuất  các đặc trưng  ( từ các lớp convolution, pooling,..) của các mô hình kinh điển."]},{"cell_type":"code","metadata":{"id":"-DFSKp46r2re","colab_type":"code","colab":{}},"source":["from keras.applications.resnet50 import ResNet50\n","from keras import backend as K\n","from keras.models import Model\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3kaAAwFBHtVc","colab_type":"text"},"source":["## ResNet50 "]},{"cell_type":"code","metadata":{"id":"xWDFd8uUr2ri","colab_type":"code","outputId":"674c3e9e-5af4-48d5-fd9b-5e2a9d04e741","executionInfo":{"status":"ok","timestamp":1561891906401,"user_tz":-420,"elapsed":38372,"user":{"displayName":"Đăng Nguyễn Hồng","photoUrl":"https://lh5.googleusercontent.com/-UTwxFgcfKfI/AAAAAAAAAAI/AAAAAAAAACY/UhcN1_QeVrs/s64/photo.jpg","userId":"01453617082147037162"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["weight_decay=1e-3\n","num_classes=5\n","base_model=ResNet50(include_top=False,weights='imagenet',input_shape=(32,32,3),classes=num_classes)\n","\n","x=base_model.output\n","\n","x = Flatten()(x)\n","\n","x = Dense(units=512, activation='relu', kernel_regularizer=l2(weight_decay))(x)\n","\n","# Layer 4\n","x = Dense(units=64, activation='relu', kernel_regularizer=l2(weight_decay))(x)\n","\n","# Layer 5\n","output = Dense(units=num_classes, activation='softmax')(x)\n","\n","model=Model(inputs=base_model.input,outputs=output)\n","model.summary()\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0630 10:51:33.464083 140201657169792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0630 10:51:33.503628 140201657169792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0630 10:51:33.515573 140201657169792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n","\n","W0630 10:51:33.551594 140201657169792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","W0630 10:51:33.552620 140201657169792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","W0630 10:51:36.648733 140201657169792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","W0630 10:51:36.729503 140201657169792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n","  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94658560/94653016 [==============================] - 1s 0us/step\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1 (Conv2D)                  (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","bn_conv1 (BatchNormalization)   (None, 16, 16, 64)   256         conv1[0][0]                      \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 16, 16, 64)   0           bn_conv1[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","res2a_branch2a (Conv2D)         (None, 8, 8, 64)     4160        max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","bn2a_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 8, 8, 64)     0           bn2a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2a_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_2[0][0]               \n","__________________________________________________________________________________________________\n","bn2a_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 8, 8, 64)     0           bn2a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2a_branch2c (Conv2D)         (None, 8, 8, 256)    16640       activation_3[0][0]               \n","__________________________________________________________________________________________________\n","res2a_branch1 (Conv2D)          (None, 8, 8, 256)    16640       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","bn2a_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn2a_branch1 (BatchNormalizatio (None, 8, 8, 256)    1024        res2a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 8, 8, 256)    0           bn2a_branch2c[0][0]              \n","                                                                 bn2a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 8, 8, 256)    0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","res2b_branch2a (Conv2D)         (None, 8, 8, 64)     16448       activation_4[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 8, 8, 64)     0           bn2b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2b_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 8, 8, 64)     0           bn2b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2b_branch2c (Conv2D)         (None, 8, 8, 256)    16640       activation_6[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 8, 8, 256)    0           bn2b_branch2c[0][0]              \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 8, 8, 256)    0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","res2c_branch2a (Conv2D)         (None, 8, 8, 64)     16448       activation_7[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 8, 8, 64)     0           bn2c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2c_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 8, 8, 64)     0           bn2c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2c_branch2c (Conv2D)         (None, 8, 8, 256)    16640       activation_9[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 8, 8, 256)    0           bn2c_branch2c[0][0]              \n","                                                                 activation_7[0][0]               \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 8, 8, 256)    0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","res3a_branch2a (Conv2D)         (None, 4, 4, 128)    32896       activation_10[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 4, 4, 128)    0           bn3a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_11[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 4, 4, 128)    0           bn3a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_12[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch1 (Conv2D)          (None, 4, 4, 512)    131584      activation_10[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn3a_branch1 (BatchNormalizatio (None, 4, 4, 512)    2048        res3a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 4, 4, 512)    0           bn3a_branch2c[0][0]              \n","                                                                 bn3a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 4, 4, 512)    0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","res3b_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 4, 4, 128)    0           bn3b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3b_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_14[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 4, 4, 128)    0           bn3b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3b_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_15[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 4, 4, 512)    0           bn3b_branch2c[0][0]              \n","                                                                 activation_13[0][0]              \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 4, 4, 512)    0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","res3c_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 4, 4, 128)    0           bn3c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3c_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_17[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 4, 4, 128)    0           bn3c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3c_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_18[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 4, 4, 512)    0           bn3c_branch2c[0][0]              \n","                                                                 activation_16[0][0]              \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 4, 4, 512)    0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","res3d_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_19[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3d_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 4, 4, 128)    0           bn3d_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3d_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_20[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3d_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 4, 4, 128)    0           bn3d_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3d_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_21[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3d_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 4, 4, 512)    0           bn3d_branch2c[0][0]              \n","                                                                 activation_19[0][0]              \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 4, 4, 512)    0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","res4a_branch2a (Conv2D)         (None, 2, 2, 256)    131328      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 2, 2, 256)    0           bn4a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_23[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 2, 2, 256)    0           bn4a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_24[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch1 (Conv2D)          (None, 2, 2, 1024)   525312      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn4a_branch1 (BatchNormalizatio (None, 2, 2, 1024)   4096        res4a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 2, 2, 1024)   0           bn4a_branch2c[0][0]              \n","                                                                 bn4a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 2, 2, 1024)   0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","res4b_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_25[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 2, 2, 256)    0           bn4b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4b_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_26[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 2, 2, 256)    0           bn4b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4b_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_27[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 2, 2, 1024)   0           bn4b_branch2c[0][0]              \n","                                                                 activation_25[0][0]              \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 2, 2, 1024)   0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","res4c_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_28[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 2, 2, 256)    0           bn4c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4c_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_29[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 2, 2, 256)    0           bn4c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4c_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_30[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 2, 2, 1024)   0           bn4c_branch2c[0][0]              \n","                                                                 activation_28[0][0]              \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 2, 2, 1024)   0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","res4d_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_31[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 2, 2, 256)    0           bn4d_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4d_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_32[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 2, 2, 256)    0           bn4d_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4d_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_33[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4d_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 2, 2, 1024)   0           bn4d_branch2c[0][0]              \n","                                                                 activation_31[0][0]              \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 2, 2, 1024)   0           add_11[0][0]                     \n","__________________________________________________________________________________________________\n","res4e_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_34[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 2, 2, 256)    0           bn4e_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4e_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_35[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 2, 2, 256)    0           bn4e_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4e_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_36[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4e_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 2, 2, 1024)   0           bn4e_branch2c[0][0]              \n","                                                                 activation_34[0][0]              \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 2, 2, 1024)   0           add_12[0][0]                     \n","__________________________________________________________________________________________________\n","res4f_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_37[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 2, 2, 256)    0           bn4f_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4f_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_38[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 2, 2, 256)    0           bn4f_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4f_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_39[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4f_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, 2, 2, 1024)   0           bn4f_branch2c[0][0]              \n","                                                                 activation_37[0][0]              \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 2, 2, 1024)   0           add_13[0][0]                     \n","__________________________________________________________________________________________________\n","res5a_branch2a (Conv2D)         (None, 1, 1, 512)    524800      activation_40[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 1, 1, 512)    0           bn5a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_41[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 1, 1, 512)    0           bn5a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_42[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch1 (Conv2D)          (None, 1, 1, 2048)   2099200     activation_40[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn5a_branch1 (BatchNormalizatio (None, 1, 1, 2048)   8192        res5a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, 1, 1, 2048)   0           bn5a_branch2c[0][0]              \n","                                                                 bn5a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 1, 1, 2048)   0           add_14[0][0]                     \n","__________________________________________________________________________________________________\n","res5b_branch2a (Conv2D)         (None, 1, 1, 512)    1049088     activation_43[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 1, 1, 512)    0           bn5b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5b_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_44[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 1, 1, 512)    0           bn5b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5b_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_45[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, 1, 1, 2048)   0           bn5b_branch2c[0][0]              \n","                                                                 activation_43[0][0]              \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 1, 1, 2048)   0           add_15[0][0]                     \n","__________________________________________________________________________________________________\n","res5c_branch2a (Conv2D)         (None, 1, 1, 512)    1049088     activation_46[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 1, 1, 512)    0           bn5c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5c_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_47[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 1, 1, 512)    0           bn5c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5c_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_48[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_16 (Add)                    (None, 1, 1, 2048)   0           bn5c_branch2c[0][0]              \n","                                                                 activation_46[0][0]              \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 1, 1, 2048)   0           add_16[0][0]                     \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 2048)         0           activation_49[0][0]              \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 512)          1049088     flatten_1[0][0]                  \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 64)           32832       dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 5)            325         dense_2[0][0]                    \n","==================================================================================================\n","Total params: 24,669,957\n","Trainable params: 24,616,837\n","Non-trainable params: 53,120\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kro5tEl3t016","colab_type":"text"},"source":["### Đóng băng toàn bộ weight ở các tầng  convolutionn. Training mô hình (các tầng fully-connected) qua một vài epochs "]},{"cell_type":"code","metadata":{"id":"6zhWr6x6r2ro","colab_type":"code","colab":{}},"source":["for layer in base_model.layers:\n","    layer.trainable = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EgEs-pcXJykt","colab_type":"code","outputId":"d997028e-1f5a-4acd-d808-e8b3ebae039e","executionInfo":{"status":"ok","timestamp":1561891906410,"user_tz":-420,"elapsed":38355,"user":{"displayName":"Đăng Nguyễn Hồng","photoUrl":"https://lh5.googleusercontent.com/-UTwxFgcfKfI/AAAAAAAAAAI/AAAAAAAAACY/UhcN1_QeVrs/s64/photo.jpg","userId":"01453617082147037162"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["from keras.optimizers import SGD\n","# compile the model (should be done *after* setting layers to non-trainable)\n","model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["W0630 10:51:46.143952 140201657169792 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"3LmHUmT6t21p","colab_type":"code","outputId":"be03ac72-470e-4e64-9721-e80458bb04af","executionInfo":{"status":"ok","timestamp":1561891920496,"user_tz":-420,"elapsed":52394,"user":{"displayName":"Đăng Nguyễn Hồng","photoUrl":"https://lh5.googleusercontent.com/-UTwxFgcfKfI/AAAAAAAAAAI/AAAAAAAAACY/UhcN1_QeVrs/s64/photo.jpg","userId":"01453617082147037162"}},"colab":{"base_uri":"https://localhost:8080/","height":785}},"source":["# train the model on the new data for a few epochs\n","model.fit(x_train,y_train,epochs=20,batch_size=x_train.shape[0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["W0630 10:51:52.766646 140201657169792 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","1672/1672 [==============================] - 4s 2ms/step - loss: 3.1499 - acc: 0.2010\n","Epoch 2/20\n","1672/1672 [==============================] - 0s 94us/step - loss: 2.9970 - acc: 0.3559\n","Epoch 3/20\n","1672/1672 [==============================] - 0s 93us/step - loss: 2.0103 - acc: 0.6262\n","Epoch 4/20\n","1672/1672 [==============================] - 0s 92us/step - loss: 1.7067 - acc: 0.7249\n","Epoch 5/20\n","1672/1672 [==============================] - 0s 93us/step - loss: 1.5749 - acc: 0.7889\n","Epoch 6/20\n","1672/1672 [==============================] - 0s 93us/step - loss: 1.4515 - acc: 0.8421\n","Epoch 7/20\n","1672/1672 [==============================] - 0s 93us/step - loss: 1.3640 - acc: 0.8923\n","Epoch 8/20\n","1672/1672 [==============================] - 0s 93us/step - loss: 1.2749 - acc: 0.9199\n","Epoch 9/20\n","1672/1672 [==============================] - 0s 93us/step - loss: 1.1970 - acc: 0.9438\n","Epoch 10/20\n","1672/1672 [==============================] - 0s 93us/step - loss: 1.1404 - acc: 0.9569\n","Epoch 11/20\n","1672/1672 [==============================] - 0s 97us/step - loss: 1.1044 - acc: 0.9629\n","Epoch 12/20\n","1672/1672 [==============================] - 0s 92us/step - loss: 1.0802 - acc: 0.9659\n","Epoch 13/20\n","1672/1672 [==============================] - 0s 93us/step - loss: 1.0595 - acc: 0.9695\n","Epoch 14/20\n","1672/1672 [==============================] - 0s 93us/step - loss: 1.0385 - acc: 0.9743\n","Epoch 15/20\n","1672/1672 [==============================] - 0s 94us/step - loss: 1.0178 - acc: 0.9833\n","Epoch 16/20\n","1672/1672 [==============================] - 0s 94us/step - loss: 1.0000 - acc: 0.9898\n","Epoch 17/20\n","1672/1672 [==============================] - 0s 93us/step - loss: 0.9857 - acc: 0.9928\n","Epoch 18/20\n","1672/1672 [==============================] - 0s 93us/step - loss: 0.9745 - acc: 0.9940\n","Epoch 19/20\n","1672/1672 [==============================] - 0s 94us/step - loss: 0.9652 - acc: 0.9946\n","Epoch 20/20\n","1672/1672 [==============================] - 0s 94us/step - loss: 0.9571 - acc: 0.9958\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f82877681d0>"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"Tkx3tMmHt3Bp","colab_type":"code","outputId":"eb842df1-7c82-4048-c698-8e38681da990","executionInfo":{"status":"ok","timestamp":1561891920499,"user_tz":-420,"elapsed":52352,"user":{"displayName":"Đăng Nguyễn Hồng","photoUrl":"https://lh5.googleusercontent.com/-UTwxFgcfKfI/AAAAAAAAAAI/AAAAAAAAACY/UhcN1_QeVrs/s64/photo.jpg","userId":"01453617082147037162"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["for i, layer in enumerate(base_model.layers):\n","   print(i, layer.name)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0 input_1\n","1 conv1_pad\n","2 conv1\n","3 bn_conv1\n","4 activation_1\n","5 pool1_pad\n","6 max_pooling2d_1\n","7 res2a_branch2a\n","8 bn2a_branch2a\n","9 activation_2\n","10 res2a_branch2b\n","11 bn2a_branch2b\n","12 activation_3\n","13 res2a_branch2c\n","14 res2a_branch1\n","15 bn2a_branch2c\n","16 bn2a_branch1\n","17 add_1\n","18 activation_4\n","19 res2b_branch2a\n","20 bn2b_branch2a\n","21 activation_5\n","22 res2b_branch2b\n","23 bn2b_branch2b\n","24 activation_6\n","25 res2b_branch2c\n","26 bn2b_branch2c\n","27 add_2\n","28 activation_7\n","29 res2c_branch2a\n","30 bn2c_branch2a\n","31 activation_8\n","32 res2c_branch2b\n","33 bn2c_branch2b\n","34 activation_9\n","35 res2c_branch2c\n","36 bn2c_branch2c\n","37 add_3\n","38 activation_10\n","39 res3a_branch2a\n","40 bn3a_branch2a\n","41 activation_11\n","42 res3a_branch2b\n","43 bn3a_branch2b\n","44 activation_12\n","45 res3a_branch2c\n","46 res3a_branch1\n","47 bn3a_branch2c\n","48 bn3a_branch1\n","49 add_4\n","50 activation_13\n","51 res3b_branch2a\n","52 bn3b_branch2a\n","53 activation_14\n","54 res3b_branch2b\n","55 bn3b_branch2b\n","56 activation_15\n","57 res3b_branch2c\n","58 bn3b_branch2c\n","59 add_5\n","60 activation_16\n","61 res3c_branch2a\n","62 bn3c_branch2a\n","63 activation_17\n","64 res3c_branch2b\n","65 bn3c_branch2b\n","66 activation_18\n","67 res3c_branch2c\n","68 bn3c_branch2c\n","69 add_6\n","70 activation_19\n","71 res3d_branch2a\n","72 bn3d_branch2a\n","73 activation_20\n","74 res3d_branch2b\n","75 bn3d_branch2b\n","76 activation_21\n","77 res3d_branch2c\n","78 bn3d_branch2c\n","79 add_7\n","80 activation_22\n","81 res4a_branch2a\n","82 bn4a_branch2a\n","83 activation_23\n","84 res4a_branch2b\n","85 bn4a_branch2b\n","86 activation_24\n","87 res4a_branch2c\n","88 res4a_branch1\n","89 bn4a_branch2c\n","90 bn4a_branch1\n","91 add_8\n","92 activation_25\n","93 res4b_branch2a\n","94 bn4b_branch2a\n","95 activation_26\n","96 res4b_branch2b\n","97 bn4b_branch2b\n","98 activation_27\n","99 res4b_branch2c\n","100 bn4b_branch2c\n","101 add_9\n","102 activation_28\n","103 res4c_branch2a\n","104 bn4c_branch2a\n","105 activation_29\n","106 res4c_branch2b\n","107 bn4c_branch2b\n","108 activation_30\n","109 res4c_branch2c\n","110 bn4c_branch2c\n","111 add_10\n","112 activation_31\n","113 res4d_branch2a\n","114 bn4d_branch2a\n","115 activation_32\n","116 res4d_branch2b\n","117 bn4d_branch2b\n","118 activation_33\n","119 res4d_branch2c\n","120 bn4d_branch2c\n","121 add_11\n","122 activation_34\n","123 res4e_branch2a\n","124 bn4e_branch2a\n","125 activation_35\n","126 res4e_branch2b\n","127 bn4e_branch2b\n","128 activation_36\n","129 res4e_branch2c\n","130 bn4e_branch2c\n","131 add_12\n","132 activation_37\n","133 res4f_branch2a\n","134 bn4f_branch2a\n","135 activation_38\n","136 res4f_branch2b\n","137 bn4f_branch2b\n","138 activation_39\n","139 res4f_branch2c\n","140 bn4f_branch2c\n","141 add_13\n","142 activation_40\n","143 res5a_branch2a\n","144 bn5a_branch2a\n","145 activation_41\n","146 res5a_branch2b\n","147 bn5a_branch2b\n","148 activation_42\n","149 res5a_branch2c\n","150 res5a_branch1\n","151 bn5a_branch2c\n","152 bn5a_branch1\n","153 add_14\n","154 activation_43\n","155 res5b_branch2a\n","156 bn5b_branch2a\n","157 activation_44\n","158 res5b_branch2b\n","159 bn5b_branch2b\n","160 activation_45\n","161 res5b_branch2c\n","162 bn5b_branch2c\n","163 add_15\n","164 activation_46\n","165 res5c_branch2a\n","166 bn5c_branch2a\n","167 activation_47\n","168 res5c_branch2b\n","169 bn5c_branch2b\n","170 activation_48\n","171 res5c_branch2c\n","172 bn5c_branch2c\n","173 add_16\n","174 activation_49\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-qhqtT3AJI2u","colab_type":"text"},"source":["## Sau khi training các tầng fully-connected , thực hiện training toàn bộ mô hình.\n","Vì các tầng convolution là một bộ trích xuất đặc trưng mạnh, ta hi vọng giữ lại trọng số của các tầng này nhiều nhất có thể.  \n","Vì vậy, learning rate được đặt là 0.001 (nhỏ)"]},{"cell_type":"code","metadata":{"id":"Oh-6EBU5t3IG","colab_type":"code","colab":{}},"source":["for layer in base_model.layers:\n","    layer.trainable = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vKmo-Fext3LT","colab_type":"code","outputId":"93696cb7-c0da-4fd8-fa60-d3b24b94be1e","executionInfo":{"status":"ok","timestamp":1561892116559,"user_tz":-420,"elapsed":248387,"user":{"displayName":"Đăng Nguyễn Hồng","photoUrl":"https://lh5.googleusercontent.com/-UTwxFgcfKfI/AAAAAAAAAAI/AAAAAAAAACY/UhcN1_QeVrs/s64/photo.jpg","userId":"01453617082147037162"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# compile the model (should be done *after* setting layers to non-trainable)\n","model.compile(optimizer=SGD(lr=0.001), loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","# train the model on the new data for a few epochs\n","model.fit(x_train,y_train,batch_size=64,epochs=100)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","1672/1672 [==============================] - 10s 6ms/step - loss: 1.1554 - acc: 0.9211\n","Epoch 2/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 1.0569 - acc: 0.9545\n","Epoch 3/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 1.0349 - acc: 0.9659\n","Epoch 4/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 1.0282 - acc: 0.9593\n","Epoch 5/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 1.0035 - acc: 0.9749\n","Epoch 6/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 1.0002 - acc: 0.9749\n","Epoch 7/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 1.0031 - acc: 0.9749\n","Epoch 8/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9969 - acc: 0.9785\n","Epoch 9/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 1.0003 - acc: 0.9737\n","Epoch 10/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9797 - acc: 0.9839\n","Epoch 11/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9749 - acc: 0.9850\n","Epoch 12/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9625 - acc: 0.9880\n","Epoch 13/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9621 - acc: 0.9886\n","Epoch 14/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9587 - acc: 0.9910\n","Epoch 15/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9457 - acc: 0.9952\n","Epoch 16/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9531 - acc: 0.9886\n","Epoch 17/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9574 - acc: 0.9892\n","Epoch 18/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9514 - acc: 0.9910\n","Epoch 19/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9449 - acc: 0.9916\n","Epoch 20/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9435 - acc: 0.9934\n","Epoch 21/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9594 - acc: 0.9892\n","Epoch 22/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9365 - acc: 0.9958\n","Epoch 23/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9451 - acc: 0.9922\n","Epoch 24/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9427 - acc: 0.9922\n","Epoch 25/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9340 - acc: 0.9970\n","Epoch 26/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9386 - acc: 0.9952\n","Epoch 27/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9296 - acc: 0.9970\n","Epoch 28/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9320 - acc: 0.9970\n","Epoch 29/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9341 - acc: 0.9946\n","Epoch 30/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9340 - acc: 0.9970\n","Epoch 31/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9333 - acc: 0.9952\n","Epoch 32/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9315 - acc: 0.9976\n","Epoch 33/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9361 - acc: 0.9964\n","Epoch 34/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9395 - acc: 0.9940\n","Epoch 35/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9359 - acc: 0.9958\n","Epoch 36/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9349 - acc: 0.9928\n","Epoch 37/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9328 - acc: 0.9982\n","Epoch 38/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9339 - acc: 0.9952\n","Epoch 39/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9287 - acc: 0.9964\n","Epoch 40/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9356 - acc: 0.9928\n","Epoch 41/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9346 - acc: 0.9940\n","Epoch 42/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9403 - acc: 0.9922\n","Epoch 43/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9366 - acc: 0.9940\n","Epoch 44/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9313 - acc: 0.9976\n","Epoch 45/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9380 - acc: 0.9934\n","Epoch 46/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9271 - acc: 0.9970\n","Epoch 47/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9305 - acc: 0.9958\n","Epoch 48/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9265 - acc: 0.9958\n","Epoch 49/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9260 - acc: 0.9970\n","Epoch 50/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9307 - acc: 0.9946\n","Epoch 51/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9479 - acc: 0.9916\n","Epoch 52/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9378 - acc: 0.9952\n","Epoch 53/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9324 - acc: 0.9940\n","Epoch 54/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9379 - acc: 0.9940\n","Epoch 55/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9420 - acc: 0.9916\n","Epoch 56/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9438 - acc: 0.9910\n","Epoch 57/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9218 - acc: 0.9988\n","Epoch 58/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9292 - acc: 0.9970\n","Epoch 59/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9263 - acc: 0.9964\n","Epoch 60/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9299 - acc: 0.9952\n","Epoch 61/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9339 - acc: 0.9934\n","Epoch 62/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9269 - acc: 0.9940\n","Epoch 63/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9251 - acc: 0.9976\n","Epoch 64/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9284 - acc: 0.9964\n","Epoch 65/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9235 - acc: 0.9982\n","Epoch 66/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9316 - acc: 0.9964\n","Epoch 67/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9374 - acc: 0.9922\n","Epoch 68/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9218 - acc: 0.9964\n","Epoch 69/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9230 - acc: 0.9976\n","Epoch 70/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9199 - acc: 0.9982\n","Epoch 71/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9207 - acc: 0.9982\n","Epoch 72/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9194 - acc: 0.9970\n","Epoch 73/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9191 - acc: 0.9988\n","Epoch 74/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9247 - acc: 0.9964\n","Epoch 75/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9242 - acc: 0.9958\n","Epoch 76/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9205 - acc: 0.9970\n","Epoch 77/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9233 - acc: 0.9964\n","Epoch 78/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9299 - acc: 0.9946\n","Epoch 79/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9230 - acc: 0.9946\n","Epoch 80/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9194 - acc: 0.9982\n","Epoch 81/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9208 - acc: 0.9958\n","Epoch 82/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9201 - acc: 0.9970\n","Epoch 83/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9212 - acc: 0.9970\n","Epoch 84/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9148 - acc: 0.9994\n","Epoch 85/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9177 - acc: 0.9988\n","Epoch 86/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9177 - acc: 0.9982\n","Epoch 87/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9216 - acc: 0.9964\n","Epoch 88/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9215 - acc: 0.9976\n","Epoch 89/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9150 - acc: 0.9982\n","Epoch 90/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9246 - acc: 0.9964\n","Epoch 91/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9138 - acc: 0.9994\n","Epoch 92/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9185 - acc: 0.9970\n","Epoch 93/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9260 - acc: 0.9934\n","Epoch 94/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9198 - acc: 0.9964\n","Epoch 95/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9203 - acc: 0.9958\n","Epoch 96/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9213 - acc: 0.9952\n","Epoch 97/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9174 - acc: 0.9982\n","Epoch 98/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9201 - acc: 0.9952\n","Epoch 99/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9144 - acc: 0.9982\n","Epoch 100/100\n","1672/1672 [==============================] - 2s 1ms/step - loss: 0.9129 - acc: 0.9988\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f82873e1470>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"wIiNdmtIr2ru","colab_type":"text"},"source":["Test model đã huấn luyện với dữ liệu test:"]},{"cell_type":"code","metadata":{"id":"yB5fXY1Ir2rw","colab_type":"code","outputId":"ee7af0f8-9b66-4f01-f537-c5d10e04f67e","executionInfo":{"status":"ok","timestamp":1561892117581,"user_tz":-420,"elapsed":249393,"user":{"displayName":"Đăng Nguyễn Hồng","photoUrl":"https://lh5.googleusercontent.com/-UTwxFgcfKfI/AAAAAAAAAAI/AAAAAAAAACY/UhcN1_QeVrs/s64/photo.jpg","userId":"01453617082147037162"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["model.evaluate(x_test, y_test)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["183/183 [==============================] - 1s 6ms/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.3094541296932867, 0.9016393432851697]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"GmlOjkjDbQ26","colab_type":"text"},"source":["## VGG16 kết hợp data augmentation để tạo thêm dữ liệu \n","Các bước tương tự như trên\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cfluDZOFbONO","colab":{}},"source":["from keras.applications.vgg16 import VGG16\n","from keras import backend as K\n","from keras.models import Model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"a4b3799f-29e9-4ac4-f281-cb7455e9be5b","executionInfo":{"status":"ok","timestamp":1561892556491,"user_tz":-420,"elapsed":5519,"user":{"displayName":"Đăng Nguyễn Hồng","photoUrl":"https://lh5.googleusercontent.com/-UTwxFgcfKfI/AAAAAAAAAAI/AAAAAAAAACY/UhcN1_QeVrs/s64/photo.jpg","userId":"01453617082147037162"}},"id":"YtVQp5qjbONT","colab":{"base_uri":"https://localhost:8080/","height":952}},"source":["weight_decay=1e-3\n","num_classes=5\n","base_model=VGG16(include_top=False,weights='imagenet',input_shape=(32,32,3),classes=num_classes)\n","\n","x=base_model.output\n","\n","x = Flatten()(x)\n","\n","x = Dense(units=512, activation='relu', kernel_regularizer=l2(weight_decay))(x)\n","\n","# Layer 4\n","x = Dense(units=64, activation='relu', kernel_regularizer=l2(weight_decay))(x)\n","\n","# Layer 5\n","output = Dense(units=num_classes, activation='softmax')(x)\n","\n","model=Model(inputs=base_model.input,outputs=output)\n","model.summary()\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 1s 0us/step\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         (None, 32, 32, 3)         0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 512)               0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 64)                32832     \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 5)                 325       \n","=================================================================\n","Total params: 15,010,501\n","Trainable params: 15,010,501\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"snQW1bWsbONa","colab":{}},"source":["for layer in base_model.layers:\n","    layer.trainable = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pdd8qqB7bONc","colab":{}},"source":["from keras.optimizers import SGD\n","model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IWKEgcC-KpQP","colab_type":"text"},"source":["**Data augmentation**   \n","Các ảnh trong tập training được xoay, miror,chỉnh sáng, và cuối cùng là normalize giá trị các pixel về khoảng [0,1]"]},{"cell_type":"code","metadata":{"id":"nD8U2ASYfdoT","colab_type":"code","colab":{}},"source":["from keras.preprocessing.image import ImageDataGenerator\n","\n","def normalize(input):\n","  return input/255.\n","datagen=ImageDataGenerator(rotation_range=30,horizontal_flip=True,preprocessing_function=normalize,brightness_range=[0.8,1.25])\n","\n","aug_gen=datagen.flow(x_train, y_train, batch_size=len(x_train),shuffle=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"4f0b3eb5-5b7a-4537-d824-d85290de01bd","executionInfo":{"status":"ok","timestamp":1561892753069,"user_tz":-420,"elapsed":174703,"user":{"displayName":"Đăng Nguyễn Hồng","photoUrl":"https://lh5.googleusercontent.com/-UTwxFgcfKfI/AAAAAAAAAAI/AAAAAAAAACY/UhcN1_QeVrs/s64/photo.jpg","userId":"01453617082147037162"}},"id":"hy9XJL1wbONr","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# train the model on the new data for a few epochs\n","model.fit_generator(aug_gen,epochs=200,steps_per_epoch=1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/200\n","1/1 [==============================] - 10s 10s/step - loss: 2.3168 - acc: 0.1758\n","Epoch 2/200\n","1/1 [==============================] - 0s 194ms/step - loss: 2.0371 - acc: 0.4510\n","Epoch 3/200\n","1/1 [==============================] - 0s 201ms/step - loss: 1.8967 - acc: 0.6352\n","Epoch 4/200\n","1/1 [==============================] - 0s 194ms/step - loss: 1.7670 - acc: 0.6633\n","Epoch 5/200\n","1/1 [==============================] - 0s 192ms/step - loss: 1.6383 - acc: 0.6788\n","Epoch 6/200\n","1/1 [==============================] - 0s 188ms/step - loss: 1.5184 - acc: 0.7057\n","Epoch 7/200\n","1/1 [==============================] - 0s 202ms/step - loss: 1.4046 - acc: 0.7380\n","Epoch 8/200\n","1/1 [==============================] - 0s 199ms/step - loss: 1.3236 - acc: 0.7620\n","Epoch 9/200\n","1/1 [==============================] - 0s 194ms/step - loss: 1.2547 - acc: 0.7739\n","Epoch 10/200\n","1/1 [==============================] - 0s 201ms/step - loss: 1.1889 - acc: 0.7871\n","Epoch 11/200\n","1/1 [==============================] - 0s 370ms/step - loss: 1.1393 - acc: 0.7996\n","Epoch 12/200\n","1/1 [==============================] - 1s 834ms/step - loss: 1.0964 - acc: 0.8116\n","Epoch 13/200\n","1/1 [==============================] - 1s 838ms/step - loss: 1.0424 - acc: 0.8188\n","Epoch 14/200\n","1/1 [==============================] - 1s 848ms/step - loss: 1.0116 - acc: 0.8236\n","Epoch 15/200\n","1/1 [==============================] - 1s 840ms/step - loss: 0.9779 - acc: 0.8254\n","Epoch 16/200\n","1/1 [==============================] - 1s 846ms/step - loss: 0.9591 - acc: 0.8260\n","Epoch 17/200\n","1/1 [==============================] - 1s 831ms/step - loss: 0.9181 - acc: 0.8445\n","Epoch 18/200\n","1/1 [==============================] - 1s 844ms/step - loss: 0.9072 - acc: 0.8451\n","Epoch 19/200\n","1/1 [==============================] - 1s 844ms/step - loss: 0.8966 - acc: 0.8385\n","Epoch 20/200\n","1/1 [==============================] - 1s 862ms/step - loss: 0.8558 - acc: 0.8511\n","Epoch 21/200\n","1/1 [==============================] - 1s 848ms/step - loss: 0.8246 - acc: 0.8642\n","Epoch 22/200\n","1/1 [==============================] - 1s 861ms/step - loss: 0.8252 - acc: 0.8618\n","Epoch 23/200\n","1/1 [==============================] - 1s 831ms/step - loss: 0.8034 - acc: 0.8630\n","Epoch 24/200\n","1/1 [==============================] - 1s 849ms/step - loss: 0.7890 - acc: 0.8654\n","Epoch 25/200\n","1/1 [==============================] - 1s 842ms/step - loss: 0.7767 - acc: 0.8630\n","Epoch 26/200\n","1/1 [==============================] - 1s 858ms/step - loss: 0.7648 - acc: 0.8708\n","Epoch 27/200\n","1/1 [==============================] - 1s 875ms/step - loss: 0.7577 - acc: 0.8624\n","Epoch 28/200\n","1/1 [==============================] - 1s 847ms/step - loss: 0.7334 - acc: 0.8804\n","Epoch 29/200\n","1/1 [==============================] - 1s 846ms/step - loss: 0.7320 - acc: 0.8690\n","Epoch 30/200\n","1/1 [==============================] - 1s 855ms/step - loss: 0.7045 - acc: 0.8846\n","Epoch 31/200\n","1/1 [==============================] - 1s 854ms/step - loss: 0.6898 - acc: 0.8876\n","Epoch 32/200\n","1/1 [==============================] - 1s 839ms/step - loss: 0.6908 - acc: 0.8840\n","Epoch 33/200\n","1/1 [==============================] - 1s 842ms/step - loss: 0.6690 - acc: 0.8941\n","Epoch 34/200\n","1/1 [==============================] - 1s 831ms/step - loss: 0.6670 - acc: 0.9001\n","Epoch 35/200\n","1/1 [==============================] - 1s 836ms/step - loss: 0.6436 - acc: 0.9013\n","Epoch 36/200\n","1/1 [==============================] - 1s 841ms/step - loss: 0.6321 - acc: 0.9061\n","Epoch 37/200\n","1/1 [==============================] - 1s 838ms/step - loss: 0.6253 - acc: 0.8959\n","Epoch 38/200\n","1/1 [==============================] - 1s 841ms/step - loss: 0.6252 - acc: 0.8983\n","Epoch 39/200\n","1/1 [==============================] - 1s 836ms/step - loss: 0.6092 - acc: 0.9097\n","Epoch 40/200\n","1/1 [==============================] - 1s 846ms/step - loss: 0.6022 - acc: 0.9127\n","Epoch 41/200\n","1/1 [==============================] - 1s 856ms/step - loss: 0.5895 - acc: 0.9151\n","Epoch 42/200\n","1/1 [==============================] - 1s 856ms/step - loss: 0.5787 - acc: 0.9151\n","Epoch 43/200\n","1/1 [==============================] - 1s 856ms/step - loss: 0.5771 - acc: 0.9079\n","Epoch 44/200\n","1/1 [==============================] - 1s 851ms/step - loss: 0.5706 - acc: 0.9199\n","Epoch 45/200\n","1/1 [==============================] - 1s 857ms/step - loss: 0.5594 - acc: 0.9127\n","Epoch 46/200\n","1/1 [==============================] - 1s 848ms/step - loss: 0.5504 - acc: 0.9151\n","Epoch 47/200\n","1/1 [==============================] - 1s 845ms/step - loss: 0.5424 - acc: 0.9264\n","Epoch 48/200\n","1/1 [==============================] - 1s 852ms/step - loss: 0.5346 - acc: 0.9205\n","Epoch 49/200\n","1/1 [==============================] - 1s 851ms/step - loss: 0.5372 - acc: 0.9211\n","Epoch 50/200\n","1/1 [==============================] - 1s 862ms/step - loss: 0.5271 - acc: 0.9187\n","Epoch 51/200\n","1/1 [==============================] - 1s 845ms/step - loss: 0.5231 - acc: 0.9163\n","Epoch 52/200\n","1/1 [==============================] - 1s 826ms/step - loss: 0.5250 - acc: 0.9085\n","Epoch 53/200\n","1/1 [==============================] - 1s 833ms/step - loss: 0.5000 - acc: 0.9300\n","Epoch 54/200\n","1/1 [==============================] - 1s 844ms/step - loss: 0.4929 - acc: 0.9282\n","Epoch 55/200\n","1/1 [==============================] - 1s 841ms/step - loss: 0.5022 - acc: 0.9276\n","Epoch 56/200\n","1/1 [==============================] - 1s 849ms/step - loss: 0.4970 - acc: 0.9240\n","Epoch 57/200\n","1/1 [==============================] - 1s 855ms/step - loss: 0.4794 - acc: 0.9330\n","Epoch 58/200\n","1/1 [==============================] - 1s 853ms/step - loss: 0.4714 - acc: 0.9372\n","Epoch 59/200\n","1/1 [==============================] - 1s 836ms/step - loss: 0.4773 - acc: 0.9342\n","Epoch 60/200\n","1/1 [==============================] - 1s 845ms/step - loss: 0.4767 - acc: 0.9276\n","Epoch 61/200\n","1/1 [==============================] - 1s 847ms/step - loss: 0.4664 - acc: 0.9366\n","Epoch 62/200\n","1/1 [==============================] - 1s 856ms/step - loss: 0.4616 - acc: 0.9378\n","Epoch 63/200\n","1/1 [==============================] - 1s 840ms/step - loss: 0.4587 - acc: 0.9336\n","Epoch 64/200\n","1/1 [==============================] - 1s 836ms/step - loss: 0.4490 - acc: 0.9444\n","Epoch 65/200\n","1/1 [==============================] - 1s 845ms/step - loss: 0.4445 - acc: 0.9396\n","Epoch 66/200\n","1/1 [==============================] - 1s 851ms/step - loss: 0.4428 - acc: 0.9408\n","Epoch 67/200\n","1/1 [==============================] - 1s 836ms/step - loss: 0.4299 - acc: 0.9414\n","Epoch 68/200\n","1/1 [==============================] - 1s 844ms/step - loss: 0.4329 - acc: 0.9474\n","Epoch 69/200\n","1/1 [==============================] - 1s 835ms/step - loss: 0.4254 - acc: 0.9450\n","Epoch 70/200\n","1/1 [==============================] - 1s 836ms/step - loss: 0.4286 - acc: 0.9372\n","Epoch 71/200\n","1/1 [==============================] - 1s 868ms/step - loss: 0.4116 - acc: 0.9474\n","Epoch 72/200\n","1/1 [==============================] - 1s 845ms/step - loss: 0.4138 - acc: 0.9432\n","Epoch 73/200\n","1/1 [==============================] - 1s 836ms/step - loss: 0.4186 - acc: 0.9420\n","Epoch 74/200\n","1/1 [==============================] - 1s 838ms/step - loss: 0.4063 - acc: 0.9462\n","Epoch 75/200\n","1/1 [==============================] - 1s 846ms/step - loss: 0.4066 - acc: 0.9444\n","Epoch 76/200\n","1/1 [==============================] - 1s 842ms/step - loss: 0.4085 - acc: 0.9468\n","Epoch 77/200\n","1/1 [==============================] - 1s 848ms/step - loss: 0.3966 - acc: 0.9456\n","Epoch 78/200\n","1/1 [==============================] - 1s 848ms/step - loss: 0.4027 - acc: 0.9456\n","Epoch 79/200\n","1/1 [==============================] - 1s 833ms/step - loss: 0.3890 - acc: 0.9533\n","Epoch 80/200\n","1/1 [==============================] - 1s 847ms/step - loss: 0.3880 - acc: 0.9474\n","Epoch 81/200\n","1/1 [==============================] - 1s 823ms/step - loss: 0.3836 - acc: 0.9468\n","Epoch 82/200\n","1/1 [==============================] - 1s 846ms/step - loss: 0.3833 - acc: 0.9474\n","Epoch 83/200\n","1/1 [==============================] - 1s 829ms/step - loss: 0.3821 - acc: 0.9504\n","Epoch 84/200\n","1/1 [==============================] - 1s 839ms/step - loss: 0.3851 - acc: 0.9432\n","Epoch 85/200\n","1/1 [==============================] - 1s 848ms/step - loss: 0.3874 - acc: 0.9408\n","Epoch 86/200\n","1/1 [==============================] - 1s 839ms/step - loss: 0.3768 - acc: 0.9480\n","Epoch 87/200\n","1/1 [==============================] - 1s 852ms/step - loss: 0.3715 - acc: 0.9522\n","Epoch 88/200\n","1/1 [==============================] - 1s 855ms/step - loss: 0.3675 - acc: 0.9545\n","Epoch 89/200\n","1/1 [==============================] - 1s 838ms/step - loss: 0.3647 - acc: 0.9510\n","Epoch 90/200\n","1/1 [==============================] - 1s 852ms/step - loss: 0.3625 - acc: 0.9563\n","Epoch 91/200\n","1/1 [==============================] - 1s 850ms/step - loss: 0.3644 - acc: 0.9504\n","Epoch 92/200\n","1/1 [==============================] - 1s 851ms/step - loss: 0.3600 - acc: 0.9510\n","Epoch 93/200\n","1/1 [==============================] - 1s 849ms/step - loss: 0.3557 - acc: 0.9593\n","Epoch 94/200\n","1/1 [==============================] - 1s 839ms/step - loss: 0.3555 - acc: 0.9510\n","Epoch 95/200\n","1/1 [==============================] - 1s 842ms/step - loss: 0.3535 - acc: 0.9522\n","Epoch 96/200\n","1/1 [==============================] - 1s 845ms/step - loss: 0.3494 - acc: 0.9539\n","Epoch 97/200\n","1/1 [==============================] - 1s 853ms/step - loss: 0.3410 - acc: 0.9587\n","Epoch 98/200\n","1/1 [==============================] - 1s 842ms/step - loss: 0.3461 - acc: 0.9522\n","Epoch 99/200\n","1/1 [==============================] - 1s 844ms/step - loss: 0.3343 - acc: 0.9641\n","Epoch 100/200\n","1/1 [==============================] - 1s 844ms/step - loss: 0.3367 - acc: 0.9611\n","Epoch 101/200\n","1/1 [==============================] - 1s 847ms/step - loss: 0.3413 - acc: 0.9611\n","Epoch 102/200\n","1/1 [==============================] - 1s 846ms/step - loss: 0.3411 - acc: 0.9528\n","Epoch 103/200\n","1/1 [==============================] - 1s 847ms/step - loss: 0.3437 - acc: 0.9551\n","Epoch 104/200\n","1/1 [==============================] - 1s 845ms/step - loss: 0.3331 - acc: 0.9605\n","Epoch 105/200\n","1/1 [==============================] - 1s 841ms/step - loss: 0.3310 - acc: 0.9569\n","Epoch 106/200\n","1/1 [==============================] - 1s 851ms/step - loss: 0.3358 - acc: 0.9551\n","Epoch 107/200\n","1/1 [==============================] - 1s 849ms/step - loss: 0.3192 - acc: 0.9659\n","Epoch 108/200\n","1/1 [==============================] - 1s 842ms/step - loss: 0.3213 - acc: 0.9581\n","Epoch 109/200\n","1/1 [==============================] - 1s 863ms/step - loss: 0.3267 - acc: 0.9569\n","Epoch 110/200\n","1/1 [==============================] - 1s 899ms/step - loss: 0.3238 - acc: 0.9653\n","Epoch 111/200\n","1/1 [==============================] - 1s 910ms/step - loss: 0.3225 - acc: 0.9593\n","Epoch 112/200\n","1/1 [==============================] - 1s 866ms/step - loss: 0.3198 - acc: 0.9653\n","Epoch 113/200\n","1/1 [==============================] - 1s 847ms/step - loss: 0.3159 - acc: 0.9587\n","Epoch 114/200\n","1/1 [==============================] - 1s 849ms/step - loss: 0.3202 - acc: 0.9629\n","Epoch 115/200\n","1/1 [==============================] - 1s 840ms/step - loss: 0.3113 - acc: 0.9605\n","Epoch 116/200\n","1/1 [==============================] - 1s 849ms/step - loss: 0.3092 - acc: 0.9623\n","Epoch 117/200\n","1/1 [==============================] - 1s 845ms/step - loss: 0.3098 - acc: 0.9671\n","Epoch 118/200\n","1/1 [==============================] - 1s 825ms/step - loss: 0.3130 - acc: 0.9593\n","Epoch 119/200\n","1/1 [==============================] - 1s 848ms/step - loss: 0.3136 - acc: 0.9635\n","Epoch 120/200\n","1/1 [==============================] - 1s 900ms/step - loss: 0.3031 - acc: 0.9683\n","Epoch 121/200\n","1/1 [==============================] - 1s 908ms/step - loss: 0.3056 - acc: 0.9647\n","Epoch 122/200\n","1/1 [==============================] - 1s 909ms/step - loss: 0.3042 - acc: 0.9671\n","Epoch 123/200\n","1/1 [==============================] - 1s 847ms/step - loss: 0.3056 - acc: 0.9629\n","Epoch 124/200\n","1/1 [==============================] - 1s 839ms/step - loss: 0.2998 - acc: 0.9677\n","Epoch 125/200\n","1/1 [==============================] - 1s 844ms/step - loss: 0.2964 - acc: 0.9689\n","Epoch 126/200\n","1/1 [==============================] - 1s 858ms/step - loss: 0.3029 - acc: 0.9593\n","Epoch 127/200\n","1/1 [==============================] - 1s 849ms/step - loss: 0.2863 - acc: 0.9689\n","Epoch 128/200\n","1/1 [==============================] - 1s 853ms/step - loss: 0.2948 - acc: 0.9647\n","Epoch 129/200\n","1/1 [==============================] - 1s 846ms/step - loss: 0.2937 - acc: 0.9671\n","Epoch 130/200\n","1/1 [==============================] - 1s 848ms/step - loss: 0.2876 - acc: 0.9749\n","Epoch 131/200\n","1/1 [==============================] - 1s 854ms/step - loss: 0.2964 - acc: 0.9629\n","Epoch 132/200\n","1/1 [==============================] - 1s 847ms/step - loss: 0.2875 - acc: 0.9641\n","Epoch 133/200\n","1/1 [==============================] - 1s 846ms/step - loss: 0.2825 - acc: 0.9695\n","Epoch 134/200\n","1/1 [==============================] - 1s 857ms/step - loss: 0.2836 - acc: 0.9677\n","Epoch 135/200\n","1/1 [==============================] - 1s 844ms/step - loss: 0.2896 - acc: 0.9671\n","Epoch 136/200\n","1/1 [==============================] - 1s 843ms/step - loss: 0.2835 - acc: 0.9671\n","Epoch 137/200\n","1/1 [==============================] - 1s 864ms/step - loss: 0.2833 - acc: 0.9689\n","Epoch 138/200\n","1/1 [==============================] - 1s 866ms/step - loss: 0.2914 - acc: 0.9641\n","Epoch 139/200\n","1/1 [==============================] - 1s 882ms/step - loss: 0.2818 - acc: 0.9707\n","Epoch 140/200\n","1/1 [==============================] - 1s 870ms/step - loss: 0.2837 - acc: 0.9647\n","Epoch 141/200\n","1/1 [==============================] - 1s 892ms/step - loss: 0.2808 - acc: 0.9659\n","Epoch 142/200\n","1/1 [==============================] - 1s 847ms/step - loss: 0.2907 - acc: 0.9665\n","Epoch 143/200\n","1/1 [==============================] - 1s 850ms/step - loss: 0.2799 - acc: 0.9701\n","Epoch 144/200\n","1/1 [==============================] - 1s 892ms/step - loss: 0.2821 - acc: 0.9677\n","Epoch 145/200\n","1/1 [==============================] - 1s 865ms/step - loss: 0.2802 - acc: 0.9689\n","Epoch 146/200\n","1/1 [==============================] - 1s 855ms/step - loss: 0.2776 - acc: 0.9719\n","Epoch 147/200\n","1/1 [==============================] - 1s 860ms/step - loss: 0.2818 - acc: 0.9623\n","Epoch 148/200\n","1/1 [==============================] - 1s 836ms/step - loss: 0.2821 - acc: 0.9617\n","Epoch 149/200\n","1/1 [==============================] - 1s 844ms/step - loss: 0.2744 - acc: 0.9719\n","Epoch 150/200\n","1/1 [==============================] - 1s 859ms/step - loss: 0.2690 - acc: 0.9701\n","Epoch 151/200\n","1/1 [==============================] - 1s 847ms/step - loss: 0.2630 - acc: 0.9719\n","Epoch 152/200\n","1/1 [==============================] - 1s 849ms/step - loss: 0.2637 - acc: 0.9737\n","Epoch 153/200\n","1/1 [==============================] - 1s 850ms/step - loss: 0.2589 - acc: 0.9749\n","Epoch 154/200\n","1/1 [==============================] - 1s 830ms/step - loss: 0.2693 - acc: 0.9731\n","Epoch 155/200\n","1/1 [==============================] - 1s 829ms/step - loss: 0.2593 - acc: 0.9785\n","Epoch 156/200\n","1/1 [==============================] - 1s 853ms/step - loss: 0.2633 - acc: 0.9743\n","Epoch 157/200\n","1/1 [==============================] - 1s 850ms/step - loss: 0.2647 - acc: 0.9683\n","Epoch 158/200\n","1/1 [==============================] - 1s 852ms/step - loss: 0.2738 - acc: 0.9653\n","Epoch 159/200\n","1/1 [==============================] - 1s 848ms/step - loss: 0.2657 - acc: 0.9677\n","Epoch 160/200\n","1/1 [==============================] - 1s 840ms/step - loss: 0.2618 - acc: 0.9719\n","Epoch 161/200\n","1/1 [==============================] - 1s 834ms/step - loss: 0.2661 - acc: 0.9695\n","Epoch 162/200\n","1/1 [==============================] - 1s 862ms/step - loss: 0.2597 - acc: 0.9725\n","Epoch 163/200\n","1/1 [==============================] - 1s 863ms/step - loss: 0.2605 - acc: 0.9695\n","Epoch 164/200\n","1/1 [==============================] - 1s 846ms/step - loss: 0.2578 - acc: 0.9737\n","Epoch 165/200\n","1/1 [==============================] - 1s 886ms/step - loss: 0.2521 - acc: 0.9767\n","Epoch 166/200\n","1/1 [==============================] - 1s 837ms/step - loss: 0.2546 - acc: 0.9713\n","Epoch 167/200\n","1/1 [==============================] - 1s 846ms/step - loss: 0.2569 - acc: 0.9713\n","Epoch 168/200\n","1/1 [==============================] - 1s 844ms/step - loss: 0.2530 - acc: 0.9731\n","Epoch 169/200\n","1/1 [==============================] - 1s 847ms/step - loss: 0.2571 - acc: 0.9701\n","Epoch 170/200\n","1/1 [==============================] - 1s 865ms/step - loss: 0.2493 - acc: 0.9767\n","Epoch 171/200\n","1/1 [==============================] - 1s 845ms/step - loss: 0.2536 - acc: 0.9713\n","Epoch 172/200\n","1/1 [==============================] - 1s 840ms/step - loss: 0.2538 - acc: 0.9725\n","Epoch 173/200\n","1/1 [==============================] - 1s 839ms/step - loss: 0.2484 - acc: 0.9749\n","Epoch 174/200\n","1/1 [==============================] - 1s 874ms/step - loss: 0.2418 - acc: 0.9791\n","Epoch 175/200\n","1/1 [==============================] - 1s 844ms/step - loss: 0.2423 - acc: 0.9809\n","Epoch 176/200\n","1/1 [==============================] - 1s 841ms/step - loss: 0.2502 - acc: 0.9695\n","Epoch 177/200\n","1/1 [==============================] - 1s 848ms/step - loss: 0.2449 - acc: 0.9743\n","Epoch 178/200\n","1/1 [==============================] - 1s 834ms/step - loss: 0.2408 - acc: 0.9743\n","Epoch 179/200\n","1/1 [==============================] - 1s 838ms/step - loss: 0.2496 - acc: 0.9695\n","Epoch 180/200\n","1/1 [==============================] - 1s 857ms/step - loss: 0.2367 - acc: 0.9785\n","Epoch 181/200\n","1/1 [==============================] - 1s 848ms/step - loss: 0.2460 - acc: 0.9767\n","Epoch 182/200\n","1/1 [==============================] - 1s 863ms/step - loss: 0.2446 - acc: 0.9749\n","Epoch 183/200\n","1/1 [==============================] - 1s 852ms/step - loss: 0.2405 - acc: 0.9803\n","Epoch 184/200\n","1/1 [==============================] - 1s 840ms/step - loss: 0.2401 - acc: 0.9731\n","Epoch 185/200\n","1/1 [==============================] - 1s 839ms/step - loss: 0.2458 - acc: 0.9707\n","Epoch 186/200\n","1/1 [==============================] - 1s 858ms/step - loss: 0.2456 - acc: 0.9707\n","Epoch 187/200\n","1/1 [==============================] - 1s 854ms/step - loss: 0.2448 - acc: 0.9719\n","Epoch 188/200\n","1/1 [==============================] - 1s 853ms/step - loss: 0.2394 - acc: 0.9785\n","Epoch 189/200\n","1/1 [==============================] - 1s 854ms/step - loss: 0.2451 - acc: 0.9719\n","Epoch 190/200\n","1/1 [==============================] - 1s 847ms/step - loss: 0.2344 - acc: 0.9767\n","Epoch 191/200\n","1/1 [==============================] - 1s 850ms/step - loss: 0.2271 - acc: 0.9809\n","Epoch 192/200\n","1/1 [==============================] - 1s 858ms/step - loss: 0.2379 - acc: 0.9731\n","Epoch 193/200\n","1/1 [==============================] - 1s 860ms/step - loss: 0.2298 - acc: 0.9773\n","Epoch 194/200\n","1/1 [==============================] - 1s 865ms/step - loss: 0.2404 - acc: 0.9731\n","Epoch 195/200\n","1/1 [==============================] - 1s 839ms/step - loss: 0.2426 - acc: 0.9695\n","Epoch 196/200\n","1/1 [==============================] - 1s 826ms/step - loss: 0.2310 - acc: 0.9773\n","Epoch 197/200\n","1/1 [==============================] - 1s 841ms/step - loss: 0.2378 - acc: 0.9683\n","Epoch 198/200\n","1/1 [==============================] - 1s 838ms/step - loss: 0.2264 - acc: 0.9833\n","Epoch 199/200\n","1/1 [==============================] - 1s 846ms/step - loss: 0.2271 - acc: 0.9797\n","Epoch 200/200\n","1/1 [==============================] - 1s 847ms/step - loss: 0.2285 - acc: 0.9809\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f81018bba90>"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"OHJ5O7zWKU8F","colab_type":"text"},"source":["Kiểm tra độ chính xác sau bước training các tầng fully-connected"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"7638cc7f-5f8f-409a-aaec-2e22be7db227","executionInfo":{"status":"ok","timestamp":1561892756369,"user_tz":-420,"elapsed":1143,"user":{"displayName":"Đăng Nguyễn Hồng","photoUrl":"https://lh5.googleusercontent.com/-UTwxFgcfKfI/AAAAAAAAAAI/AAAAAAAAACY/UhcN1_QeVrs/s64/photo.jpg","userId":"01453617082147037162"}},"id":"QZ7uoL-obONx","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["model.evaluate(x_test/255,y_test/255)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["183/183 [==============================] - 0s 486us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.1502167450599983, 0.8469945345420004]"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NAJT0YmbbON5","colab":{}},"source":["for layer in base_model.layers:\n","    layer.trainable = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"1f85dd22-b1fa-4ba7-cb93-fc83d79ada09","executionInfo":{"status":"ok","timestamp":1561892865748,"user_tz":-420,"elapsed":105348,"user":{"displayName":"Đăng Nguyễn Hồng","photoUrl":"https://lh5.googleusercontent.com/-UTwxFgcfKfI/AAAAAAAAAAI/AAAAAAAAACY/UhcN1_QeVrs/s64/photo.jpg","userId":"01453617082147037162"}},"id":"2sR0hWh5bON8","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# compile the model (should be done *after* setting layers to non-trainable)\n","model.compile(optimizer=SGD(lr=0.001), loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","# train the model on the new data for a few epochs\n","model.fit_generator(aug_gen,epochs=100,steps_per_epoch=1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","1/1 [==============================] - 16s 16s/step - loss: 0.2281 - acc: 0.9749\n","Epoch 2/100\n","1/1 [==============================] - 1s 584ms/step - loss: 0.2338 - acc: 0.9779\n","Epoch 3/100\n","1/1 [==============================] - 1s 604ms/step - loss: 0.2448 - acc: 0.9695\n","Epoch 4/100\n","1/1 [==============================] - 1s 591ms/step - loss: 0.3393 - acc: 0.9252\n","Epoch 5/100\n","1/1 [==============================] - 1s 590ms/step - loss: 1.2534 - acc: 0.7183\n","Epoch 6/100\n","1/1 [==============================] - 1s 586ms/step - loss: 3.6821 - acc: 0.5855\n","Epoch 7/100\n","1/1 [==============================] - 1s 595ms/step - loss: 1.0143 - acc: 0.6968\n","Epoch 8/100\n","1/1 [==============================] - 1s 585ms/step - loss: 0.8370 - acc: 0.7368\n","Epoch 9/100\n","1/1 [==============================] - 1s 593ms/step - loss: 0.4809 - acc: 0.8774\n","Epoch 10/100\n","1/1 [==============================] - 1s 591ms/step - loss: 0.4027 - acc: 0.9079\n","Epoch 11/100\n","1/1 [==============================] - 1s 604ms/step - loss: 0.3713 - acc: 0.9276\n","Epoch 12/100\n","1/1 [==============================] - 1s 597ms/step - loss: 0.3498 - acc: 0.9324\n","Epoch 13/100\n","1/1 [==============================] - 1s 603ms/step - loss: 0.3361 - acc: 0.9360\n","Epoch 14/100\n","1/1 [==============================] - 1s 598ms/step - loss: 0.3209 - acc: 0.9378\n","Epoch 15/100\n","1/1 [==============================] - 1s 605ms/step - loss: 0.3011 - acc: 0.9438\n","Epoch 16/100\n","1/1 [==============================] - 1s 601ms/step - loss: 0.3033 - acc: 0.9468\n","Epoch 17/100\n","1/1 [==============================] - 1s 607ms/step - loss: 0.2915 - acc: 0.9557\n","Epoch 18/100\n","1/1 [==============================] - 1s 607ms/step - loss: 0.2803 - acc: 0.9581\n","Epoch 19/100\n","1/1 [==============================] - 1s 611ms/step - loss: 0.2780 - acc: 0.9593\n","Epoch 20/100\n","1/1 [==============================] - 1s 612ms/step - loss: 0.2726 - acc: 0.9593\n","Epoch 21/100\n","1/1 [==============================] - 1s 611ms/step - loss: 0.2594 - acc: 0.9671\n","Epoch 22/100\n","1/1 [==============================] - 1s 609ms/step - loss: 0.2529 - acc: 0.9695\n","Epoch 23/100\n","1/1 [==============================] - 1s 624ms/step - loss: 0.2500 - acc: 0.9683\n","Epoch 24/100\n","1/1 [==============================] - 1s 964ms/step - loss: 0.2458 - acc: 0.9701\n","Epoch 25/100\n","1/1 [==============================] - 1s 962ms/step - loss: 0.2458 - acc: 0.9713\n","Epoch 26/100\n","1/1 [==============================] - 1s 961ms/step - loss: 0.2404 - acc: 0.9683\n","Epoch 27/100\n","1/1 [==============================] - 1s 976ms/step - loss: 0.2332 - acc: 0.9749\n","Epoch 28/100\n","1/1 [==============================] - 1s 972ms/step - loss: 0.2372 - acc: 0.9749\n","Epoch 29/100\n","1/1 [==============================] - 1s 954ms/step - loss: 0.2358 - acc: 0.9719\n","Epoch 30/100\n","1/1 [==============================] - 1s 967ms/step - loss: 0.2294 - acc: 0.9749\n","Epoch 31/100\n","1/1 [==============================] - 1s 958ms/step - loss: 0.2258 - acc: 0.9797\n","Epoch 32/100\n","1/1 [==============================] - 1s 973ms/step - loss: 0.2241 - acc: 0.9767\n","Epoch 33/100\n","1/1 [==============================] - 1s 967ms/step - loss: 0.2173 - acc: 0.9827\n","Epoch 34/100\n","1/1 [==============================] - 1s 967ms/step - loss: 0.2267 - acc: 0.9779\n","Epoch 35/100\n","1/1 [==============================] - 1s 969ms/step - loss: 0.2234 - acc: 0.9785\n","Epoch 36/100\n","1/1 [==============================] - 1s 965ms/step - loss: 0.2146 - acc: 0.9833\n","Epoch 37/100\n","1/1 [==============================] - 1s 959ms/step - loss: 0.2177 - acc: 0.9809\n","Epoch 38/100\n","1/1 [==============================] - 1s 966ms/step - loss: 0.2180 - acc: 0.9803\n","Epoch 39/100\n","1/1 [==============================] - 1s 968ms/step - loss: 0.2154 - acc: 0.9797\n","Epoch 40/100\n","1/1 [==============================] - 1s 956ms/step - loss: 0.2119 - acc: 0.9809\n","Epoch 41/100\n","1/1 [==============================] - 1s 970ms/step - loss: 0.2107 - acc: 0.9815\n","Epoch 42/100\n","1/1 [==============================] - 1s 959ms/step - loss: 0.2166 - acc: 0.9791\n","Epoch 43/100\n","1/1 [==============================] - 1s 969ms/step - loss: 0.2216 - acc: 0.9785\n","Epoch 44/100\n","1/1 [==============================] - 1s 953ms/step - loss: 0.2100 - acc: 0.9827\n","Epoch 45/100\n","1/1 [==============================] - 1s 954ms/step - loss: 0.2083 - acc: 0.9844\n","Epoch 46/100\n","1/1 [==============================] - 1s 969ms/step - loss: 0.2148 - acc: 0.9827\n","Epoch 47/100\n","1/1 [==============================] - 1s 961ms/step - loss: 0.2056 - acc: 0.9862\n","Epoch 48/100\n","1/1 [==============================] - 1s 968ms/step - loss: 0.2079 - acc: 0.9803\n","Epoch 49/100\n","1/1 [==============================] - 1s 991ms/step - loss: 0.2091 - acc: 0.9815\n","Epoch 50/100\n","1/1 [==============================] - 1s 959ms/step - loss: 0.2011 - acc: 0.9868\n","Epoch 51/100\n","1/1 [==============================] - 1s 957ms/step - loss: 0.2027 - acc: 0.9827\n","Epoch 52/100\n","1/1 [==============================] - 1s 936ms/step - loss: 0.2019 - acc: 0.9862\n","Epoch 53/100\n","1/1 [==============================] - 1s 949ms/step - loss: 0.2064 - acc: 0.9856\n","Epoch 54/100\n","1/1 [==============================] - 1s 947ms/step - loss: 0.2062 - acc: 0.9844\n","Epoch 55/100\n","1/1 [==============================] - 1s 962ms/step - loss: 0.1984 - acc: 0.9874\n","Epoch 56/100\n","1/1 [==============================] - 1s 964ms/step - loss: 0.1988 - acc: 0.9886\n","Epoch 57/100\n","1/1 [==============================] - 1s 975ms/step - loss: 0.2056 - acc: 0.9839\n","Epoch 58/100\n","1/1 [==============================] - 1s 951ms/step - loss: 0.1979 - acc: 0.9862\n","Epoch 59/100\n","1/1 [==============================] - 1s 1s/step - loss: 0.1947 - acc: 0.9874\n","Epoch 60/100\n","1/1 [==============================] - 1s 967ms/step - loss: 0.1961 - acc: 0.9862\n","Epoch 61/100\n","1/1 [==============================] - 1s 996ms/step - loss: 0.1992 - acc: 0.9874\n","Epoch 62/100\n","1/1 [==============================] - 1s 978ms/step - loss: 0.2019 - acc: 0.9886\n","Epoch 63/100\n","1/1 [==============================] - 1s 989ms/step - loss: 0.2035 - acc: 0.9833\n","Epoch 64/100\n","1/1 [==============================] - 1s 980ms/step - loss: 0.1958 - acc: 0.9880\n","Epoch 65/100\n","1/1 [==============================] - 1s 986ms/step - loss: 0.2007 - acc: 0.9839\n","Epoch 66/100\n","1/1 [==============================] - 1s 961ms/step - loss: 0.1962 - acc: 0.9880\n","Epoch 67/100\n","1/1 [==============================] - 1s 975ms/step - loss: 0.1923 - acc: 0.9892\n","Epoch 68/100\n","1/1 [==============================] - 1s 972ms/step - loss: 0.1991 - acc: 0.9844\n","Epoch 69/100\n","1/1 [==============================] - 1s 995ms/step - loss: 0.1963 - acc: 0.9886\n","Epoch 70/100\n","1/1 [==============================] - 1s 1s/step - loss: 0.1960 - acc: 0.9856\n","Epoch 71/100\n","1/1 [==============================] - 1s 962ms/step - loss: 0.1938 - acc: 0.9868\n","Epoch 72/100\n","1/1 [==============================] - 1s 966ms/step - loss: 0.1901 - acc: 0.9910\n","Epoch 73/100\n","1/1 [==============================] - 1s 966ms/step - loss: 0.1983 - acc: 0.9844\n","Epoch 74/100\n","1/1 [==============================] - 1s 978ms/step - loss: 0.1910 - acc: 0.9892\n","Epoch 75/100\n","1/1 [==============================] - 1s 971ms/step - loss: 0.1913 - acc: 0.9904\n","Epoch 76/100\n","1/1 [==============================] - 1s 959ms/step - loss: 0.1935 - acc: 0.9898\n","Epoch 77/100\n","1/1 [==============================] - 1s 965ms/step - loss: 0.1948 - acc: 0.9880\n","Epoch 78/100\n","1/1 [==============================] - 1s 952ms/step - loss: 0.1927 - acc: 0.9868\n","Epoch 79/100\n","1/1 [==============================] - 1s 963ms/step - loss: 0.1922 - acc: 0.9880\n","Epoch 80/100\n","1/1 [==============================] - 1s 981ms/step - loss: 0.1863 - acc: 0.9904\n","Epoch 81/100\n","1/1 [==============================] - 1s 975ms/step - loss: 0.1895 - acc: 0.9892\n","Epoch 82/100\n","1/1 [==============================] - 1s 964ms/step - loss: 0.1879 - acc: 0.9916\n","Epoch 83/100\n","1/1 [==============================] - 1s 961ms/step - loss: 0.1881 - acc: 0.9922\n","Epoch 84/100\n","1/1 [==============================] - 1s 964ms/step - loss: 0.1889 - acc: 0.9886\n","Epoch 85/100\n","1/1 [==============================] - 1s 966ms/step - loss: 0.1919 - acc: 0.9910\n","Epoch 86/100\n","1/1 [==============================] - 1s 959ms/step - loss: 0.1912 - acc: 0.9916\n","Epoch 87/100\n","1/1 [==============================] - 1s 970ms/step - loss: 0.1937 - acc: 0.9868\n","Epoch 88/100\n","1/1 [==============================] - 1s 961ms/step - loss: 0.1831 - acc: 0.9940\n","Epoch 89/100\n","1/1 [==============================] - 1s 956ms/step - loss: 0.1916 - acc: 0.9886\n","Epoch 90/100\n","1/1 [==============================] - 1s 962ms/step - loss: 0.1893 - acc: 0.9910\n","Epoch 91/100\n","1/1 [==============================] - 1s 961ms/step - loss: 0.1918 - acc: 0.9856\n","Epoch 92/100\n","1/1 [==============================] - 1s 994ms/step - loss: 0.1877 - acc: 0.9904\n","Epoch 93/100\n","1/1 [==============================] - 1s 979ms/step - loss: 0.1901 - acc: 0.9922\n","Epoch 94/100\n","1/1 [==============================] - 1s 967ms/step - loss: 0.1854 - acc: 0.9904\n","Epoch 95/100\n","1/1 [==============================] - 1s 967ms/step - loss: 0.1897 - acc: 0.9880\n","Epoch 96/100\n","1/1 [==============================] - 1s 974ms/step - loss: 0.1883 - acc: 0.9916\n","Epoch 97/100\n","1/1 [==============================] - 1s 971ms/step - loss: 0.1819 - acc: 0.9934\n","Epoch 98/100\n","1/1 [==============================] - 1s 972ms/step - loss: 0.1837 - acc: 0.9928\n","Epoch 99/100\n","1/1 [==============================] - 1s 974ms/step - loss: 0.1861 - acc: 0.9898\n","Epoch 100/100\n","1/1 [==============================] - 1s 968ms/step - loss: 0.1826 - acc: 0.9934\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f81018bbda0>"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ncpTOkbUbOOC"},"source":["Test model đã huấn luyện với dữ liệu test:"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"4ce4a4da-7fa8-478a-ac4c-adeed9e8580a","executionInfo":{"status":"ok","timestamp":1561892995607,"user_tz":-420,"elapsed":2119,"user":{"displayName":"Đăng Nguyễn Hồng","photoUrl":"https://lh5.googleusercontent.com/-UTwxFgcfKfI/AAAAAAAAAAI/AAAAAAAAACY/UhcN1_QeVrs/s64/photo.jpg","userId":"01453617082147037162"}},"id":"J62MJ9abbOOD","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["model.evaluate(x_test/255, y_test/255)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["183/183 [==============================] - 1s 7ms/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.15002270718741287, 0.9016393406795022]"]},"metadata":{"tags":[]},"execution_count":40}]}]}